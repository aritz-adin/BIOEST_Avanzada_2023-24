[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bioestadística Avanzada / Curso 2023-24",
    "section": "",
    "text": "Linear Mixed Models\nGeneralized Linear Mixed Models"
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "Bioestadística Avanzada / Curso 2023-24",
    "section": "",
    "text": "Linear Mixed Models\nGeneralized Linear Mixed Models"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Bioestadística Avanzada / Curso 2023-24",
    "section": "References",
    "text": "References\nPinheiro, J.C., and Bates, D.M. (2000). Mixed-effects Models in S and S-PLUS. Springer.\nZuur, A.F., Hilbe, J.M., and Ieno, E.N. (2013). A Beginner’s Guide to GLM and GLMM with R. Highland Statistics Ltd."
  },
  {
    "objectID": "Chapter1_Exercises.html",
    "href": "Chapter1_Exercises.html",
    "title": "Chapter 1: Linear Mixed Models",
    "section": "",
    "text": "Exercise 1: plasma data\nBelow are the results of a randomised complete block experiment to compare the effects on the clotting time of plasma (mins) of four different methods for the treatment of plasma. Samples of plasma were taken from a random sample of 8 volunteers and were subjected to all 4 treatments.\n\n\n\n\nTreatment\n\n\n\n\n\n\n\nVolunteer\n1\n2\n3\n4\n\n\n1\n8.4\n9.4\n9.8\n12.2\n\n\n2\n12.8\n15.2\n12.9\n14.4\n\n\n3\n9.6\n9.1\n11.2\n9.8\n\n\n4\n9.8\n8.8\n9.9\n12.0\n\n\n5\n8.4\n8.2\n8.5\n8.5\n\n\n6\n8.6\n9.9\n9.8\n10.9\n\n\n7\n8.9\n9.0\n9.2\n10.4\n\n\n8\n7.9\n8.1\n8.2\n10.0\n\n\n\n\n1. Load the data intored in the Plasma.txt file, convert Volunteer and Treatment variables to factor, and make a descriptive plot to visualize differences between treatments and/or subjects.\n\nPlasma &lt;- read.table(\"Plasma.txt\", header=TRUE)\nhead(Plasma, n=8)\n\n  Volunteer Treatment Clotting\n1         1         1      8.4\n2         1         2      9.4\n3         1         3      9.8\n4         1         4     12.2\n5         2         1     12.8\n6         2         2     15.2\n7         2         3     12.9\n8         2         4     14.4\n\nPlasma$Volunteer &lt;- as.factor(Plasma$Volunteer)\nPlasma$Treatment &lt;- as.factor(Plasma$Treatment)\nstr(Plasma)\n\n'data.frame':   32 obs. of  3 variables:\n $ Volunteer: Factor w/ 8 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 2 2 2 2 3 3 ...\n $ Treatment: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 3 4 1 2 3 4 1 2 ...\n $ Clotting : num  8.4 9.4 9.8 12.2 12.8 15.2 12.9 14.4 9.6 9.1 ...\n\n\nWe can make a descriptive plot of the data using the ggplot2 package\n\nlibrary(ggplot2)\n\nggplot(Plasma, aes(x=Clotting, y=Volunteer, color=Treatment)) +\n  geom_point() +\n  labs(x=\"Clotting time (mins)\", y=\"Volunteer\") +\n  theme_minimal()\n\n\n\n\nWe observe systematic differences between subjects and treatments.\n\n\n2. Which variable should be included as a fixed effect, and which as a random effect? Make a design plot to visually compare the magnitude of the effects of the Treatment and Volunteer factors.\n\nWe want to compare these particular types of treatments (experimental factor), so we use fixed effects for the Type factor.\nThe eight subjects represents a sample from the population about which we wish to make inferences (random factor), so we use random effects to model the Volunteer factor.\n\n\nplot.design(Clotting ~ Treatment*Volunteer, data=Plasma)\n\n\n\n\nAverage clotting time for each level of the factors Treatment and Volunteer\n\n\n\n\n\nWe see that the variability associated with the Treatment factor is lower than the variability associated with the Volunteer factor.\nWe also see that the average clotting time according to the treatment type is in the order \\(T1 \\leq T2 \\leq T3 \\leq T4\\).\n\n\n\n3. Write the linear mixed model equation.\n\\[y_{ij} = \\beta_j + u_i + \\epsilon_{ij}, \\quad i=1,\\ldots,8, \\quad j=1,\\ldots,4,\\] \\[u_i \\sim N(0,\\sigma^2_u), \\quad \\epsilon_{ij} \\sim N(0,\\sigma^2)\\] where\n\n\\(\\beta_j\\) is the mean clotting time from the \\(j\\)-th treatment\n\\(u_i\\) is a random variable associated with the \\(i\\)-th treatment\n\\(\\epsilon_{ij}\\) are independent random errors\n\nUsing matrix notation\n\\[\\boldsymbol{y} = \\begin{pmatrix} \\boldsymbol{I}_4 \\\\ \\vdots \\\\ \\boldsymbol{I}_4 \\end{pmatrix} \\begin{pmatrix} \\beta_1 \\\\ \\vdots \\\\ \\beta_4 \\end{pmatrix} +\n\\begin{pmatrix}\n\\boldsymbol{1}_4 & \\boldsymbol{0} & \\ldots & \\boldsymbol{0} \\\\\n\\boldsymbol{0} & \\boldsymbol{1}_4 & \\ldots & \\boldsymbol{0} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\boldsymbol{0} & \\boldsymbol{0} & \\cdots & \\boldsymbol{1}_4 \\\\\n\\end{pmatrix} \\boldsymbol{u} + \\boldsymbol{\\epsilon}\\]\nor using Kronecker products\n\\[y = (\\boldsymbol{1}_8 \\otimes \\boldsymbol{I}_4)\\boldsymbol{\\beta} + (\\boldsymbol{I}_8 \\otimes \\boldsymbol{1}_4)\\boldsymbol{u} + \\boldsymbol{\\epsilon}\\]\n\n\n4. Choose the correct structure for the random effects\n\n## Fit the models ##\nlibrary(lme4)\n\nplasma.null &lt;- lm(Clotting ~ -1 + Treatment, data=Plasma)\nplasma.lmer &lt;- lmer(Clotting ~ -1 + Treatment + (1|Volunteer), data=Plasma)\n\n## LRT for the variance component sigma2_u ##\nLRT &lt;- -2*(logLik(plasma.null,REML=T)-logLik(plasma.lmer,REML=T))\nmean(pchisq(LRT,df=c(0,1),lower.tail=F))\n\n[1] 2.290542e-07\n\n## Using the ranova() function from lmerTest package ##\nlibrary(lmerTest)\n\nWarning: package 'lmerTest' was built under R version 4.3.2\n\nranova(plasma.lmer)\n\nANOVA-like table for random-effects: Single term deletions\n\nModel:\nClotting ~ Treatment + (1 | Volunteer) - 1\n                npar  logLik    AIC    LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;             6 -47.943 107.89                         \n(1 | Volunteer)    5 -60.659 131.32 25.433  1  4.581e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nranova(plasma.lmer)[2,6]/2\n\n[1] 2.290542e-07\n\n## We can also use the AIC/BIC to compare the models ##\nModels &lt;- list(plasma.null=plasma.null, plasma.lmer=plasma.lmer)\ncbind(AIC=lapply(Models, AIC), BIC=lapply(Models, BIC))\n\n            AIC      BIC     \nplasma.null 134.8699 142.1986\nplasma.lmer 107.8852 116.6796\n\n\n\n\n5. Check if the treatment effect is significant.\nWe compare nested models (with and without Treatment factor) using the LRT with the anova() function base on fitting through the ML method\n\nM1 &lt;- lmer(Clotting ~ 1 + (1|Volunteer), data=Plasma, REML=FALSE)\nM2 &lt;- lmer(Clotting ~ -1 + Treatment + (1|Volunteer), data=Plasma, REML=FALSE)\nanova(M1,M2)\n\nData: Plasma\nModels:\nM1: Clotting ~ 1 + (1 | Volunteer)\nM2: Clotting ~ -1 + Treatment + (1 | Volunteer)\n   npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)   \nM1    3 117.77 122.17 -55.885  111.770                        \nM2    6 107.80 116.60 -47.902   95.804 15.966  3   0.001152 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe conclude that the Treatment effect is significant.\n\n\n6. Verify whether the model assumptions are satisfied.\na) Assessing assumptions on the within-group errors\n\nplot(plasma.lmer)\n\n\n\nplot(plasma.lmer, Volunteer ~ resid(., type=\"pearson\"), abline=0, lty=2)\n\n\n\nres &lt;- resid(plasma.lmer, type=\"pearson\")\nqqnorm(res)\nqqline(res)\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.94578, p-value = 0.1093\n\n\n\nWe observe that the residuals are centered at zero and normally distributed, but there seems to be a lack of constant variance in the residuals (heterocedasticy).\n\nb) Assessing assumptions on the random-effects\n\nu &lt;- unlist(ranef(plasma.lmer)$Volunteer)\nqqnorm(u)\nqqline(u)\n\n\n\nshapiro.test(u)\n\n\n    Shapiro-Wilk normality test\n\ndata:  u\nW = 0.76565, p-value = 0.01215\n\n\n\nAgain, the are some issues with the assumptions for the random effects.\n\n\n\n7. Examine the model results (estimated fixed effects and variance components). Compute and interpret the intra-class correlation coefficient. Compute the predicted random effects and fitted values.\na) Estimated fixed effects and 95% confidence intervals\n\nfixef(plasma.lmer)\n\nTreatment1 Treatment2 Treatment3 Treatment4 \n    9.3000     9.7125     9.9375    11.0250 \n\nvcov(plasma.lmer)\n\n4 x 4 Matrix of class \"dpoMatrix\"\n           Treatment1 Treatment2 Treatment3 Treatment4\nTreatment1  0.4141183  0.3321317  0.3321317  0.3321317\nTreatment2  0.3321317  0.4141183  0.3321317  0.3321317\nTreatment3  0.3321317  0.3321317  0.4141183  0.3321317\nTreatment4  0.3321317  0.3321317  0.3321317  0.4141183\n\nbeta.CI &lt;- confint(plasma.lmer, parm=\"beta_\")\n\nComputing profile confidence intervals ...\n\nbeta.CI\n\n              2.5 %   97.5 %\nTreatment1 8.000009 10.59999\nTreatment2 8.412509 11.01249\nTreatment3 8.637509 11.23749\nTreatment4 9.725009 12.32499\n\nj &lt;- 4\nplot(1:j, fixef(plasma.lmer), pch=19, cex=0.5, xaxt=\"n\",\n     xlim=0.5+c(0,j), ylim=range(c(beta.CI))*c(0.9,1.1),\n     xlab=\"Type\", ylab=\"Estimated fixed effects\")\naxis(1, at=1:j, labels=rownames(beta.CI))\nsegments(1:j, beta.CI[,\"2.5 %\"], 1:j, beta.CI[,\"97.5 %\"])\n\n\n\n\nWe can use the emmeans() function to compute pairwise comparisons between treatments\n\nlibrary(emmeans)\nemmeans(plasma.lmer, pairwise~Treatment, infer=T)\n\n$emmeans\n Treatment emmean    SE   df lower.CL upper.CL t.ratio p.value\n 1           9.30 0.644 9.56     7.86     10.7  14.452  &lt;.0001\n 2           9.71 0.644 9.56     8.27     11.2  15.093  &lt;.0001\n 3           9.94 0.644 9.56     8.49     11.4  15.442  &lt;.0001\n 4          11.03 0.644 9.56     9.58     12.5  17.132  &lt;.0001\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n$contrasts\n contrast                estimate    SE df lower.CL upper.CL t.ratio p.value\n Treatment1 - Treatment2   -0.412 0.405 21    -1.54   0.7162  -1.019  0.7405\n Treatment1 - Treatment3   -0.637 0.405 21    -1.77   0.4912  -1.574  0.4139\n Treatment1 - Treatment4   -1.725 0.405 21    -2.85  -0.5963  -4.260  0.0018\n Treatment2 - Treatment3   -0.225 0.405 21    -1.35   0.9037  -0.556  0.9440\n Treatment2 - Treatment4   -1.312 0.405 21    -2.44  -0.1838  -3.241  0.0189\n Treatment3 - Treatment4   -1.087 0.405 21    -2.22   0.0412  -2.686  0.0616\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 4 estimates \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nTwo out of six pairwise comparisons are statistically significant at the 5% level:\n\nThe mean clotting time for treatment 4 is significantly longer than that for treatments 1 and 2.\n\nb) Estimated variance components and 95% confidence intervals\n\nVarCorr(plasma.lmer)\n\n Groups    Name        Std.Dev.\n Volunteer (Intercept) 1.63005 \n Residual              0.80987 \n\nconfint(plasma.lmer, parm=\"theta_\")\n\nComputing profile confidence intervals ...\n\n\n           2.5 %   97.5 %\n.sig01 0.9562558 2.794239\n.sigma 0.5849697 1.035247\n\n\nIntra-class correlation coefficient: \\(\\rho=\\frac{\\sigma^2_u}{\\sigma^2_u+\\sigma^2} = \\frac{1.63^2}{1.63^2+0.81^2}=0.802\\). Which means that 80.1% of the overall variability can be attributed to the differences between the individuals.\nc) Compute the predicted random effects and fitted values\n\nt(ranef(plasma.lmer)$Volunteer)\n\n                      1        2           3        4         5          6\n(Intercept) -0.04120702 3.608557 -0.06475388 0.123621 -1.501113 -0.1824882\n                     7         8\n(Intercept) -0.5827849 -1.359832\n\nplasma.fitted &lt;- cbind(Plasma,\n                       Clotting.fit=fitted(plasma.lmer),\n                       error=resid(plasma.lmer))\nplasma.fitted\n\n   Volunteer Treatment Clotting Clotting.fit       error\n1          1         1      8.4     9.258793 -0.85879298\n2          1         2      9.4     9.671293 -0.27129298\n3          1         3      9.8     9.896293 -0.09629298\n4          1         4     12.2    10.983793  1.21620702\n5          2         1     12.8    12.908557 -0.10855720\n6          2         2     15.2    13.321057  1.87894280\n7          2         3     12.9    13.546057 -0.64605720\n8          2         4     14.4    14.633557 -0.23355720\n9          3         1      9.6     9.235246  0.36475388\n10         3         2      9.1     9.647746 -0.54774612\n11         3         3     11.2     9.872746  1.32725388\n12         3         4      9.8    10.960246 -1.16024612\n13         4         1      9.8     9.423621  0.37637895\n14         4         2      8.8     9.836121 -1.03612105\n15         4         3      9.9    10.061121 -0.16112105\n16         4         4     12.0    11.148621  0.85137895\n17         5         1      8.4     7.798887  0.60111270\n18         5         2      8.2     8.211387 -0.01138730\n19         5         3      8.5     8.436387  0.06361270\n20         5         4      8.5     9.523887 -1.02388730\n21         6         1      8.6     9.117512 -0.51751179\n22         6         2      9.9     9.530012  0.36998821\n23         6         3      9.8     9.755012  0.04498821\n24         6         4     10.9    10.842512  0.05748821\n25         7         1      8.9     8.717215  0.18278493\n26         7         2      9.0     9.129715 -0.12971507\n27         7         3      9.2     9.354715 -0.15471507\n28         7         4     10.4    10.442215 -0.04221507\n29         8         1      7.9     7.940168 -0.04016849\n30         8         2      8.1     8.352668 -0.25266849\n31         8         3      8.2     8.577668 -0.37766849\n32         8         4     10.0     9.665168  0.33483151\n\n\n\n\n\nExercise 2: spider data\nOxbrough et al. (2005) investigated how spider communities change over forestation cycles in conifer and broadleaf plantations. They identified environmental and structural features of the habitat than can be used as indicators of spider biodiversity. Different plots were surveyed, each comprising 5 to 7 sampling sites separated by a minimum of 50 metres. More than 100 species of spiders were observed.\nThe Spiders.txt file contains some of the data recorded from the original study. We are interested in analyzing the relationship between the spider diversity in each site with some environmental explanatory variables. The data set contains the following variables:\n\nDivIndex: Variable of interest. Lower values of this index indicates less abundance of different species.\nHerbLayer: Percentage of Herb Layer Cover\nLitter: Percentage of Litter Content\nGroundVeg: Percentage of Ground Vegetation\nPlot: Factor indicating the surveyed plot.\n\n\n1. Load the data intored in the Spiders.txt file and convert Plot variable to factor. Make descriptive graphs to visualize relationships between the variable of interest and the explanatory variables, taking into account the Plot factor.\n\nSpiders &lt;- read.table(\"Spiders.txt\", header=T)\nSpiders$Plot &lt;- as.factor(Spiders$Plot)\nstr(Spiders)\n\n'data.frame':   168 obs. of  5 variables:\n $ DivIndex : num  1.05 1.13 1 0.87 0.94 1.01 1.2 0.38 0.71 0.82 ...\n $ HerbLayer: num  0.27 0.45 0.63 0.49 0.32 0.73 0.68 0.2 0.39 0.38 ...\n $ GroundVeg: num  0.01 0.01 0.01 0.01 0.03 0.27 0.15 0.15 0.59 0.35 ...\n $ Litter   : num  0 0 0 0 0 0 0 0.63 0.06 0.49 ...\n $ Plot     : Factor w/ 30 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 1 1 1 2 2 2 ...\n\n\nWe can make descriptive graphs of the data using the ggplot2 package\n\nlibrary(ggplot2)\n\nggplot(Spiders, aes(x=HerbLayer, y=DivIndex, color=Plot)) +\n  geom_point() +\n  labs(x=\"Percentage of Herb Layer Cover\", y=\"Diversity Index\") +\n  theme_minimal()\n\n\n\nggplot(Spiders, aes(x=Litter, y=DivIndex, color=Plot)) +\n  geom_point() +\n  labs(x=\"Percentage of Litter Content\", y=\"Diversity Index\") +\n  theme_minimal()\n\n\n\nggplot(Spiders, aes(x=GroundVeg, y=DivIndex, color=Plot)) +\n  geom_point() +\n  labs(x=\"Percentage of Ground Vegetation\", y=\"Diversity Index\") +\n  theme_minimal()\n\n\n\n\nDesign graph to compare average diversity indexes for each level of the Plot factor\n\nplot.design(DivIndex ~ Plot, data=Spiders)\n\n\n\n\n\n\n2. Choose the correct structure for the random effects\n\n## Fit the models ##\nlibrary(lme4)\n\nspiders.null &lt;- lm(DivIndex ~ 1 + HerbLayer + Litter + GroundVeg, data=Spiders)\nspiders.lmer &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + GroundVeg + (1|Plot), data=Spiders)\n\n## LRT for the variance component sigma2_u ##\nLRT &lt;- -2*(logLik(spiders.null,REML=T)-logLik(spiders.lmer,REML=T))\nmean(pchisq(LRT,df=c(0,1),lower.tail=F))\n\n[1] 0.0002102636\n\n## Using the ranova() function from lmerTest package ##\nlibrary(lmerTest)\nranova(spiders.lmer)\n\nANOVA-like table for random-effects: Single term deletions\n\nModel:\nDivIndex ~ HerbLayer + Litter + GroundVeg + (1 | Plot)\n           npar logLik     AIC    LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;        6 98.715 -185.43                         \n(1 | Plot)    5 92.495 -174.99 12.439  1  0.0004205 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nranova(spiders.lmer)[2,6]/2\n\n[1] 0.0002102636\n\n\n\n\n3. Check which environmental variables should be included in the model.\nWe compare nested models:\n\nM0 &lt;- lmer(DivIndex ~ 1 + (1|Plot), data=Spiders, REML=FALSE)\nM1 &lt;- lmer(DivIndex ~ 1 + HerbLayer + (1|Plot), data=Spiders, REML=FALSE)\nM2 &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + (1|Plot), data=Spiders, REML=FALSE)\nM3 &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + GroundVeg + (1|Plot), data=Spiders, REML=FALSE)\nanova(M0,M1,M2,M3)\n\nData: Spiders\nModels:\nM0: DivIndex ~ 1 + (1 | Plot)\nM1: DivIndex ~ 1 + HerbLayer + (1 | Plot)\nM2: DivIndex ~ 1 + HerbLayer + Litter + (1 | Plot)\nM3: DivIndex ~ 1 + HerbLayer + Litter + GroundVeg + (1 | Plot)\n   npar     AIC     BIC  logLik deviance   Chisq Df Pr(&gt;Chisq)    \nM0    3 -186.68 -177.31  96.339  -192.68                          \nM1    4 -198.50 -186.01 103.252  -206.50 13.8261  1  0.0002005 ***\nM2    5 -205.88 -190.26 107.940  -215.88  9.3759  1  0.0021985 ** \nM3    6 -204.26 -185.52 108.132  -216.26  0.3830  1  0.5360224    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe conclude that the only the HerbLayer and Litter covariates are statistically significant.\nWe can also check if a interaction between these two variables should be included in the model\n\nM4 &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + HerbLayer*Litter + (1|Plot), data=Spiders, REML=FALSE)\nanova(M2,M4)\n\nData: Spiders\nModels:\nM2: DivIndex ~ 1 + HerbLayer + Litter + (1 | Plot)\nM4: DivIndex ~ 1 + HerbLayer + Litter + HerbLayer * Litter + (1 | Plot)\n   npar     AIC     BIC logLik deviance  Chisq Df Pr(&gt;Chisq)\nM2    5 -205.88 -190.26 107.94  -215.88                     \nM4    6 -204.09 -185.34 108.05  -216.09 0.2089  1     0.6476\n\n\n\n\n4. Fit the final linear mixed model and write its equation\nWe fit the following linear mixed model \\[y_{ij} = \\beta_0 + \\beta_1 \\times HerbLayer_{ij} + \\beta_2 \\times Litter_{ij} + u_i + \\epsilon_{ij}\\] \\[u_i \\sim N(0,\\sigma^2_u), \\quad \\epsilon_{ij} \\sim N(0,\\sigma^2)\\] where\n\n\\(y_{ij}\\) is the diversity index at site \\(j\\) in plot \\(i\\)\n\\(\\beta_0\\) is a global intercept\n\\(\\beta_1\\) and \\(\\beta_2\\) are regression coefficients associated with the continuous covariates HerbLayer and Litter, respectively\n\\(u_i\\) is a random variable associated with the \\(i\\)-th surveyed plot\n\\(\\epsilon_{ij}\\) are independent random errors\n\n\n## Final model ##\nlibrary(lme4)\n\nModel &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + (1|Plot), data=Spiders)\nsummary(Model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: DivIndex ~ 1 + HerbLayer + Litter + (1 | Plot)\n   Data: Spiders\n\nREML criterion at convergence: -201.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6298 -0.4518  0.0329  0.5959  2.6373 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Plot     (Intercept) 0.004145 0.06438 \n Residual             0.013854 0.11770 \nNumber of obs: 168, groups:  Plot, 30\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   0.93674    0.01994  51.53734  46.985  &lt; 2e-16 ***\nHerbLayer     0.16628    0.04301 127.12493   3.866 0.000175 ***\nLitter       -0.22189    0.07077 157.44148  -3.135 0.002048 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr) HrbLyr\nHerbLayer -0.609       \nLitter    -0.278  0.026\n\n\n\n\n5. Verify whether the model assumptions are satisfied.\na) Assessing assumptions on the within-group errors\n\nplot(Model)\n\n\n\nplot(Model, Plot ~ resid(., type=\"pearson\"), abline=0, lty=2)\n\n\n\nres &lt;- resid(Model, type=\"pearson\")\nqqnorm(res)\nqqline(res)\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.96873, p-value = 0.0007681\n\n\nb) Assessing assumptions on the random effects\n\nu &lt;- unlist(ranef(Model)$Plot)\nqqnorm(u)\nqqline(u)\n\n\n\nshapiro.test(u)\n\n\n    Shapiro-Wilk normality test\n\ndata:  u\nW = 0.96304, p-value = 0.3695\n\n\n\n\n6. Examine the model results (estimated fixed effects and variance components). Compute and interpret the intra-class correlation coefficient. Make a plot of observed vs predicted diversity index values.\na) Estimated fixed effects and 95% confidence intervals\n\nfixef(Model)\n\n(Intercept)   HerbLayer      Litter \n  0.9367414   0.1662767  -0.2218901 \n\nbeta.CI &lt;- confint(Model, parm=\"beta_\")\n\nComputing profile confidence intervals ...\n\nbeta.CI\n\n                  2.5 %     97.5 %\n(Intercept)  0.89767549  0.9755674\nHerbLayer    0.08255604  0.2501822\nLitter      -0.36550678 -0.0822844\n\n\nb) Estimated variance components and 95% confidence intervals\n\nVarCorr(Model)\n\n Groups   Name        Std.Dev.\n Plot     (Intercept) 0.064379\n Residual             0.117703\n\nconfint(Model, parm=\"theta_\")\n\nComputing profile confidence intervals ...\n\n\n            2.5 %     97.5 %\n.sig01 0.03582034 0.09292245\n.sigma 0.10450819 0.13254556\n\n\nIntra-class correlation coefficient: \\(\\rho=\\frac{\\sigma^2_u}{\\sigma^2_u+\\sigma^2} = \\frac{0.0644^2}{0.0644^2+0.1177^2}=0.802\\). Which means that only 23% of the overall variability can be attributed to the differences between the surveyed plots.\nc) Compare observed and predicted diversity index values\n\nspiders.fitted &lt;- cbind(Spiders,\n                        DivIndex.fit=fitted(Model),\n                        error=resid(Model))\nhead(spiders.fitted)\n\n  DivIndex HerbLayer GroundVeg Litter Plot DivIndex.fit       error\n1     1.05      0.27      0.01      0    1    0.9863934  0.06360665\n2     1.13      0.45      0.01      0    1    1.0163232  0.11367684\n3     1.00      0.63      0.01      0    1    1.0462530 -0.04625298\n4     0.87      0.49      0.01      0    1    1.0229742 -0.15297423\n5     0.94      0.32      0.03      0    1    0.9947072 -0.05470719\n6     1.01      0.73      0.27      0    1    1.0628806 -0.05288065\n\nplot(spiders.fitted$DivIndex, spiders.fitted$DivIndex.fit,\n     xlab=\"Observed\", ylab=\"Predicted\", main=\"Diversity Index\",\n     xlim=c(0.4,1.5), ylim=c(0.4,1.5))\nlines(c(0,2),c(0,2))\n\n\n\n\n\n\n\nExercise 3: split-plot experiment on varieties of oats\nThese data have been introduced by Yates (1935) as an example of a split-plot design. The experimental units were arranged into six block using a \\(3 \\times 4\\) full factorial design, with three varieties of oats and four nitrogen concentrations. The term full factorial means that every variety was used with every nitrogen concentration.\n\nOats &lt;- read.table(\"Oats.txt\", header=T, stringsAsFactors = T)\nhead(Oats, n=12)\n\n   Block     Variety nitro yield\n1      I     Victory   0.0   111\n2      I     Victory   0.2   130\n3      I     Victory   0.4   157\n4      I     Victory   0.6   174\n5      I Golden Rain   0.0   117\n6      I Golden Rain   0.2   114\n7      I Golden Rain   0.4   161\n8      I Golden Rain   0.6   141\n9      I  Marvellous   0.0   105\n10     I  Marvellous   0.2   140\n11     I  Marvellous   0.4   118\n12     I  Marvellous   0.6   156\n\nstr(Oats)\n\n'data.frame':   72 obs. of  4 variables:\n $ Block  : Factor w/ 6 levels \"I\",\"II\",\"III\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Variety: Factor w/ 3 levels \"Golden Rain\",..: 3 3 3 3 1 1 1 1 2 2 ...\n $ nitro  : num  0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 ...\n $ yield  : int  111 130 157 174 117 114 161 141 105 140 ...\n\nlibrary(ggplot2)\n\nggplot(Oats, aes(x=factor(nitro), y=yield, color=Variety)) +\n  geom_line(aes(group=Variety)) + \n  geom_point() + \n  labs(x=\"Nitrogen concentration\", y=\"Yield\") +\n  ggtitle(\"Yield of oats by variety and nitrogen level\") +\n  facet_wrap(~ Block, ncol=2) +\n  theme_minimal()\n\n\n\n\nDesign graph to compare average yields for each level of Block, Variety and nitro factors\n\nplot.design(yield ~ Block*Variety*factor(nitro), data=Oats)\n\n\n\n\n\n1. Choose the correct structure for the random effects\nWe fit linear mixed models with all the fixed effects and different nested structures of random effects\n\nlibrary(lme4)\n\nM0 &lt;- lm(yield ~ 1 + Variety*factor(nitro), data=Oats)\nM1 &lt;- lmer(yield ~ 1 + Variety*factor(nitro) + (1|Block), data=Oats)\nM2 &lt;- lmer(yield ~ 1 + Variety*factor(nitro) + (1|Block) + (1|Block:Variety), data=Oats)\n\nLRT for the variance component of the Block random effect\n\ntest01 &lt;- -2*(logLik(M0,REML=T)-logLik(M1,REML=T))\nmean(pchisq(test01,df=c(0,1),lower.tail=F))\n\n[1] 7.178078e-08\n\n\nLRT for the variance component of the Block:Variety interaction random effect\n\ntest12 &lt;- -2*(logLik(M1,REML=T)-logLik(M2,REML=T))\nmean(pchisq(test12,df=c(0,1),lower.tail=F))\n\n[1] 0.002820642\n\n\n\n\n2. Choose the correct structure for the fixed effects\nAgain, we compare nested models with different structures of fixed effects\n\nM2a &lt;- lmer(yield ~ 1 + (1|Block) + (1|Block:Variety), data=Oats, REML=FALSE)\nM2b &lt;- lmer(yield ~ 1 + Variety + (1|Block) + (1|Block:Variety), data=Oats, REML=FALSE)\n\nboundary (singular) fit: see help('isSingular')\n\nM2c &lt;- lmer(yield ~ 1 + Variety + factor(nitro) + (1|Block) + (1|Block:Variety), data=Oats, REML=FALSE)\nM2d &lt;- lmer(yield ~ 1 + Variety*factor(nitro) + (1|Block) + (1|Block:Variety), data=Oats, REML=FALSE)\nanova(M2a,M2b,M2c,M2d)\n\nData: Oats\nModels:\nM2a: yield ~ 1 + (1 | Block) + (1 | Block:Variety)\nM2b: yield ~ 1 + Variety + (1 | Block) + (1 | Block:Variety)\nM2c: yield ~ 1 + Variety + factor(nitro) + (1 | Block) + (1 | Block:Variety)\nM2d: yield ~ 1 + Variety * factor(nitro) + (1 | Block) + (1 | Block:Variety)\n    npar    AIC    BIC  logLik deviance   Chisq Df Pr(&gt;Chisq)    \nM2a    4 675.48 684.59 -333.74   667.48                          \nM2b    6 676.37 690.03 -332.19   664.37  3.1113  2     0.2110    \nM2c    9 616.04 636.53 -299.02   598.04 66.3295  3  2.606e-14 ***\nM2d   15 625.91 660.06 -297.95   595.91  2.1375  6     0.9066    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe conclude that only the nitrogen level should be included as a significant fixed effect.\n\n\n3. Fit the final linear mixed model and write its equation\nWe fit the following linear mixed model \\[y_{ijk} = \\beta_k + u_i + v_{ij} + \\epsilon_{ijk}\\] \\[u_i \\sim N(0,\\sigma^2_u), \\quad v_{ij} \\sim N(0,\\sigma^2_v), \\quad \\epsilon_{ijk} \\sim N(0,\\sigma^2)\\] where\n\n\\(y_{ijk}\\) is the yield in block \\(i\\) for oat variety \\(j\\) and nitrogen concentration level \\(k\\)\n\\(\\beta_k\\) is the mean yield for nitrogen concentration level \\(k\\)\n\\(u_i\\) is a random variable associated with the \\(i\\)-th block\n\\(v_{ij}\\) is a interaction random variable associated with variety \\(j\\) within the \\(i\\)-th block\n\\(\\epsilon_{ijk}\\) are independent random errors\n\n\n## Final model ##\nlibrary(lme4)\n\nModel &lt;- lmer(yield ~ -1 + factor(nitro) + (1|Block) + (1|Block:Variety), data=Oats)\nsummary(Model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: yield ~ -1 + factor(nitro) + (1 | Block) + (1 | Block:Variety)\n   Data: Oats\n\nREML criterion at convergence: 582.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.78156 -0.61169  0.02222  0.62201  1.68138 \n\nRandom effects:\n Groups        Name        Variance Std.Dev.\n Block:Variety (Intercept) 121.9    11.04   \n Block         (Intercept) 210.4    14.51   \n Residual                  162.6    12.75   \nNumber of obs: 72, groups:  Block:Variety, 18; Block, 6\n\nFixed effects:\n                 Estimate Std. Error      df t value Pr(&gt;|t|)    \nfactor(nitro)0     79.389      7.132   6.639   11.13 1.55e-05 ***\nfactor(nitro)0.2   98.889      7.132   6.639   13.87 3.80e-06 ***\nfactor(nitro)0.4  114.222      7.132   6.639   16.02 1.49e-06 ***\nfactor(nitro)0.6  123.389      7.132   6.639   17.30 9.05e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            fct()0 f()0.2 f()0.4\nfctr(nt)0.2 0.822               \nfctr(nt)0.4 0.822  0.822        \nfctr(nt)0.6 0.822  0.822  0.822 \n\n\n\n\n4. Verify whether the model assumptions are satisfied.\na) Assessing assumptions on the within-group errors\n\nplot(Model)\n\n\n\nplot(Model, Block ~ resid(., type=\"pearson\"), abline=0, lty=2)\n\n\n\nplot(Model, Block:Variety ~ resid(., type=\"pearson\"), abline=0, lty=2)\n\n\n\nres &lt;- resid(Model, type=\"pearson\")\nqqnorm(res)\nqqline(res)\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.98128, p-value = 0.3599\n\n\nb) Assessing assumptions on the random-effects\n\nu &lt;- t(ranef(Model)$Block)\nqqnorm(u)\nqqline(u)\n\n\n\nshapiro.test(u)\n\n\n    Shapiro-Wilk normality test\n\ndata:  u\nW = 0.76965, p-value = 0.03081\n\nv &lt;- t(ranef(Model)$`Block:Variety`)\nqqnorm(v)\nqqline(v)\n\n\n\nshapiro.test(v)\n\n\n    Shapiro-Wilk normality test\n\ndata:  v\nW = 0.97555, p-value = 0.893\n\n\n\n\n5. Examine the model results.\na) Estimated fixed effects and 95% confidence intervals\n\nfixef(Model)\n\n  factor(nitro)0 factor(nitro)0.2 factor(nitro)0.4 factor(nitro)0.6 \n        79.38889         98.88889        114.22222        123.38889 \n\nbeta.CI &lt;- confint(Model, parm=\"beta_\")\n\nComputing profile confidence intervals ...\n\nbeta.CI\n\n                     2.5 %    97.5 %\nfactor(nitro)0    64.68016  94.09762\nfactor(nitro)0.2  84.18016 113.59762\nfactor(nitro)0.4  99.51349 128.93095\nfactor(nitro)0.6 108.68016 138.09762\n\nj &lt;- 4\nplot(1:j, fixef(Model), pch=19, cex=0.5, xaxt=\"n\",\n     xlim=0.5+c(0,j), ylim=range(c(beta.CI))*c(0.9,1.1),\n     xlab=\"Nitro\", ylab=\"Estimated fixed effects\")\naxis(1, at=1:j, labels=c(\"0\",\"0.2\",\"0.4\",\"0.6\"))\nsegments(1:j, beta.CI[,\"2.5 %\"], 1:j, beta.CI[,\"97.5 %\"])\n\n\n\nlibrary(emmeans)\nemmeans(Model, pairwise~factor(nitro), infer=T)\n\n$emmeans\n nitro emmean   SE   df lower.CL upper.CL t.ratio p.value\n   0.0   79.4 7.13 6.64     62.3     96.4  11.131  &lt;.0001\n   0.2   98.9 7.13 6.64     81.8    115.9  13.865  &lt;.0001\n   0.4  114.2 7.13 6.64     97.2    131.3  16.015  &lt;.0001\n   0.6  123.4 7.13 6.64    106.3    140.4  17.300  &lt;.0001\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n$contrasts\n contrast            estimate   SE df lower.CL upper.CL t.ratio p.value\n nitro0 - nitro0.2     -19.50 4.25 51    -30.8    -8.21  -4.588  0.0002\n nitro0 - nitro0.4     -34.83 4.25 51    -46.1   -23.55  -8.196  &lt;.0001\n nitro0 - nitro0.6     -44.00 4.25 51    -55.3   -32.71 -10.353  &lt;.0001\n nitro0.2 - nitro0.4   -15.33 4.25 51    -26.6    -4.05  -3.608  0.0038\n nitro0.2 - nitro0.6   -24.50 4.25 51    -35.8   -13.21  -5.765  &lt;.0001\n nitro0.4 - nitro0.6    -9.17 4.25 51    -20.5     2.12  -2.157  0.1493\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 4 estimates \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nb) Estimated variance components and 95% confidence intervals\n\nVarCorr(Model)\n\n Groups        Name        Std.Dev.\n Block:Variety (Intercept) 11.039  \n Block         (Intercept) 14.506  \n Residual                  12.750  \n\nconfint(Model, parm=\"theta_\")\n\nComputing profile confidence intervals ...\n\n\n           2.5 %   97.5 %\n.sig01  6.282056 19.25237\n.sig02  3.211632 28.86249\n.sigma 10.375961 15.15269\n\ncor1 &lt;- 14.506^2/(11.039^2+14.506^2+12.75^2)\ncor1\n\n[1] 0.4252313\n\ncor2 &lt;- 11.039^2/(11.039^2+14.506^2+12.75^2)\ncor2\n\n[1] 0.2462574\n\n\n\n\\(\\frac{\\sigma^2_u}{\\sigma^2_u+\\sigma^2_v+\\sigma^2}=0.425\\), which mean that 42.5% of the overall variability can be attributed to the main block effect.\n\\(\\frac{\\sigma^2_v}{\\sigma^2_u+\\sigma^2_v+\\sigma^2}=0.246\\), which mean that 24.6% of the overall variability can be attributed to the interaction effect.\n\nc) Predicted random effects and yield values\n\nt(ranef(Model)$Block)\n\n                  I       II       III        IV         V        VI\n(Intercept) 24.9411 2.606775 -6.406482 -4.617085 -10.38292 -6.141386\n\nt(ranef(Model)$`Block:Variety`)\n\n            I:Golden Rain I:Marvellous I:Victory II:Golden Rain II:Marvellous\n(Intercept)      3.252073    0.6274271  10.56358       5.002576      11.00177\n            II:Victory III:Golden Rain III:Marvellous III:Victory\n(Intercept)  -14.49479        -8.11071       15.69857   -11.29778\n            IV:Golden Rain IV:Marvellous IV:Victory V:Golden Rain V:Marvellous\n(Intercept)       6.482771     -3.265912  -5.890557      1.432829    -6.253633\n            V:Victory VI:Golden Rain VI:Marvellous VI:Victory\n(Intercept) -1.191817      -5.684859      8.375741  -6.247284\n\nOats.fitted &lt;- data.frame(Oats,\n                          yield.fit=fitted(Model),\n                          yield.error=resid(Model))\nhead(Oats.fitted)\n\n  Block     Variety nitro yield yield.fit yield.error\n1     I     Victory   0.0   111  114.8936   -3.893569\n2     I     Victory   0.2   130  134.3936   -4.393569\n3     I     Victory   0.4   157  149.7269    7.273097\n4     I     Victory   0.6   174  158.8936   15.106431\n5     I Golden Rain   0.0   117  107.5821    9.417943\n6     I Golden Rain   0.2   114  127.0821  -13.082057"
  },
  {
    "objectID": "Chapter2_Exercises.html",
    "href": "Chapter2_Exercises.html",
    "title": "Chapter 2: Generalized Linear Mixed Models",
    "section": "",
    "text": "Exercise 1\nData from a clinical trial, involving 2 treatments (control and active drug), conducted at 8 randomly selected centers are discussed by Beitler and Landis (1985). For the \\(i\\)-th center and \\(j\\)-th treatment, the proportion of \\(n_{ij}\\) patients having a positive response (\\(y_{ij}\\)) is recorded below.\n\n\n\nCentre\nTreatment\n\\(y_{ij}\\)\n\\(n_{ij}\\)\n\n\n\n\n1\ndrug\n11\n36\n\n\n1\ncontrol\n10\n37\n\n\n2\ndrug\n16\n20\n\n\n2\ncontrol\n22\n32\n\n\n3\ndrug\n14\n19\n\n\n3\ncontrol\n7\n19\n\n\n\\(\\ldots\\)\n\\(\\ldots\\)\n\\(\\ldots\\)\n\\(\\ldots\\)\n\n\n\n\n1. Load the data intored in the multicentre.txt file, convert centre variables to factor, and make a descriptive plot to visualize differences between treatments and/or centers.\n\nmulticentre &lt;- read.table(file=\"multicentre.txt\", header=T, stringsAsFactors=T)\nhead(multicentre)\n\n  centre   treat  y  n       obs\n1      1    drug 11 36 0.3055556\n2      1 control 10 37 0.2702703\n3      2    drug 16 20 0.8000000\n4      2 control 22 32 0.6875000\n5      3    drug 14 19 0.7368421\n6      3 control  7 19 0.3684211\n\nmulticentre$centre &lt;- as.factor(multicentre$centre)\nstr(multicentre)\n\n'data.frame':   22 obs. of  5 variables:\n $ centre: Factor w/ 11 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 2 2 3 3 4 4 5 5 ...\n $ treat : Factor w/ 2 levels \"control\",\"drug\": 2 1 2 1 2 1 2 1 2 1 ...\n $ y     : int  11 10 16 22 14 7 2 1 6 0 ...\n $ n     : int  36 37 20 32 19 19 16 17 17 12 ...\n $ obs   : num  0.306 0.27 0.8 0.688 0.737 ...\n\n\nWe can make a descriptive plot of the data using the ggplot2 package\n\nlibrary(ggplot2)\n\nlibrary(ggplot2)\nggplot(multicentre, aes(x=obs, y=centre, color=treat)) +\n  geom_point() +\n  labs(x=\"Observed probability\", y=\"Centre\")\n\n\n\n\nWe observe systematic differences between centres.\n\n\n2. Which variable should be included as a fixed effect, and which as a random effect? Make a design plot to visually compare the magnitude of the effects of the centre and treat factors.\n\nWe want to compare these particular treatments (experimental factor), so we use fixed effects for the treat factor.\nThe eight centres represents a random sample from the population about which we wish to make inferences (random factor), so we use random effects to model the center factor.\n\n\nplot.design(obs ~ centre*treat, data=multicentre)\n\n\n\n\nAverage observed probabilities for each level of the factors treat and center\n\n\n\n\n\nWe see that the variability associated with the treatment is much lower than the variability associated with the centres.\nWe also see that the average probability of a positive response is lower in the active drug treatment.\n\n\n\n3. Write the mixed logistic regression model equation.\n\\[y_{ij} | u_i  \\sim Bin(n_{ij},\\pi_{ij}), \\quad i=1,\\ldots,10 \\quad \\mbox{and} \\quad j=1,2\\] \\[\\mbox{logit}(\\pi_{ij}) = \\beta_0 + \\beta_1*x_{j} + u_i, \\quad u_i \\sim N(0,\\sigma_u^2)\\] where\n\n\\(\\pi_{ij}\\) is the probability of a favourable outcome in a patient on the \\(i\\)-th centre and \\(j\\)-th treatment\n\\(x_j\\) is an indicator variable for treatment (0=control, 1=active drug)\n\\(u_i\\) is a random variable associated with the \\(i\\)-th centre\n\n\n\n4. Choose the correct structure for the random effects\n\n## Fit the models ##\nlibrary(lme4)\n\nM0 &lt;- glm(obs ~ 1 + treat, family=\"binomial\", weights=n, data=multicentre)\nM1 &lt;- glmer(obs ~ 1 + treat + (1|centre), family=\"binomial\", weights=n, data=multicentre)\n\n## LRT for the variance component sigma2_u ##\nLRT &lt;- -2*(logLik(M0)-logLik(M1))\nmean(pchisq(LRT,df=c(0,1),lower.tail=F))\n\n[1] 3.910022e-15\n\n## We can also use the AIC/BIC to compare the models ##\nModels &lt;- list(multicentre.glm=M0, multicentre.glmer=M1)\ncbind(AIC=lapply(Models, AIC), BIC=lapply(Models, BIC))\n\n                  AIC      BIC     \nmulticentre.glm   196.8286 199.0107\nmulticentre.glmer 138.4485 141.7216\n\n\n\n\n5. Check if the treatment effect is significant.\nWe compare nested models (with and without treat factor) using the LRT with the anova() function\n\nM1a &lt;- glmer(obs ~ 1 + (1|centre), family=\"binomial\", weights=n, data=multicentre)\nM1b &lt;- glmer(obs ~ 1 + treat + (1|centre), family=\"binomial\", weights=n, data=multicentre)\nanova(M1a,M1b)\n\nData: multicentre\nModels:\nM1a: obs ~ 1 + (1 | centre)\nM1b: obs ~ 1 + treat + (1 | centre)\n    npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)\nM1a    2 136.63 138.82 -66.317   132.63                     \nM1b    3 138.45 141.72 -66.224   132.45 0.1862  1     0.6661\n\n\nWe conclude that the treatment effect is not statistically significant.\n\n\n6. Using the model with fixed and random effects, interpret the odds ratio \\(e^{\\beta_1}\\) and compute a 95% confidence interval. Which is the median probability of a positive response on the control group?\n\nlibrary(emmeans)\nemmeans(M1b, revpairwise~treat, type=\"response\", inf=TRUE)\n\n$emmeans\n treat    prob     SE  df asymp.LCL asymp.UCL null z.ratio p.value\n control 0.359 0.0892 Inf     0.208     0.545  0.5  -1.497  0.1345\n drug    0.376 0.0911 Inf     0.220     0.564  0.5  -1.301  0.1932\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the logit scale \nTests are performed on the logit scale \n\n$contrasts\n contrast       odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value\n drug / control       1.08 0.186 Inf     0.768      1.51    1   0.433  0.6651\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log odds ratio scale \nTests are performed on the log odds ratio scale \n\n\n\nThe estimated odds of a patient showing a positive response on the active drug group relative to the control group is 1.08 with a 95% confidence interval of \\([0.77, 1.51]\\).\nThe median (for \\(u_i=0\\)) probability of a positive response over a population of centres under the control group is \\(\\hat{\\pi}_i=0.376\\) with a 95% confidence interval of \\([0.220, 0.564]\\).\n\n\n\n7. Using the best model, verify whether the model assumptions on the random effects are satisfied.\n\nModel &lt;- M1a\n\nrand &lt;- unlist(ranef(Model)$centre)\nqqnorm(rand)\nqqline(rand)\n\n\n\nshapiro.test(rand)\n\n\n    Shapiro-Wilk normality test\n\ndata:  rand\nW = 0.93053, p-value = 0.4162\n\n\nWe don’t reject the null hypothesis of normality of the random effects.\n\n\n8. Which is the estimated variance and 95% confidence interval of the within-centre random effect? Compute and interpret the intra-class correlation coefficient.\n\nVarCorr(Model)\n\n Groups Name        Std.Dev.\n centre (Intercept) 1.1692  \n\nconfint(Model, parm=\"theta_\")\n\nComputing profile confidence intervals ...\n\n\n          2.5 %   97.5 %\n.sig01 0.709846 2.060211\n\n\nWe can compute the intra-class correlation coefficient as \\[\\rho=\\frac{\\sigma^2_u}{\\sigma^2_u+3.29}=1.169^2/(1.169^2+3.29) = 0.29347,\\] which means that 29% of the overall variability can be attributed to the differences between centres.\n\n\n9. Compute the predicted probabilties of a positive response for each value of the dataset. Include those estimated probabilities in the descriptive plot of section 1).\n\nmulticentre$pred &lt;- predict(Model, newdata=multicentre, type=\"response\")\nhead(multicentre)\n\n  centre   treat  y  n       obs      pred\n1      1    drug 11 36 0.3055556 0.3337400\n2      1 control 10 37 0.2702703 0.3337400\n3      2    drug 16 20 0.8000000 0.5178894\n4      2 control 22 32 0.6875000 0.5178894\n5      3    drug 14 19 0.7368421 0.4391549\n6      3 control  7 19 0.3684211 0.4391549\n\nggplot(multicentre, aes(x=obs, y=centre, color=treat)) +\n  geom_point() +\n  geom_point(aes(x=pred, y=centre), shape=8, color=\"black\") + \n  labs(x=\"Prob\", y=\"Centre\")\n\n\n\n\nObserved (dots) and predicted (asterisks) probabilities of a positive response for each centre"
  },
  {
    "objectID": "Chapter1_Exercises.html#table-of-contents",
    "href": "Chapter1_Exercises.html#table-of-contents",
    "title": "Chapter 1: Linear Mixed Models",
    "section": "",
    "text": "Exercise 1: plasma data\nExercise 2: spider data"
  }
]